services:
  nlp-sagemaker:
    build:
      context: ./aws_sagemaker/
      args:
        http_proxy: ${http_proxy}
        https_proxy: ${https_proxy}
        no_proxy: ${no_proxy}
      dockerfile: ./Dockerfile
    command: sh -c "jupyter nbconvert --to python 1.0-intel-sagemaker-inference.ipynb && python3 1.0-intel-sagemaker-inference.py"
    environment:
      - http_proxy=${http_proxy}
      - https_proxy=${https_proxy}
      - no_proxy=${no_proxy}
      - AWS_PROFILE=${AWS_PROFILE}
    image: ${FINAL_IMAGE_NAME}:inference-ubuntu-20.04
    network_mode: "host"
    privileged: true
    volumes:
      - ${OUTPUT_DIR}:${OUTPUT_DIR}
      - ./aws_sagemaker/notebooks:/root/notebooks
      - ./aws_sagemaker/src:/root/src
      - ./aws_data/.aws:/root/.aws
    working_dir: /root/notebooks
